\chapter{Deployment Guide for Ecto-\/\+Trigger}
\hypertarget{md_guides_2deployment}{}\label{md_guides_2deployment}\index{Deployment Guide for Ecto-\/Trigger@{Deployment Guide for Ecto-\/Trigger}}
\label{md_guides_2deployment_autotoc_md16}%
\Hypertarget{md_guides_2deployment_autotoc_md16}%


This guide explains how to run a trained Ecto-\/\+Trigger model on real devices in the field. We provide instructions for two supported platforms\+:



{\bfseries{Raspberry Pi}}\begin{adjustwidth}{1em}{0em}


To execute the models on Raspberry Pi systems, you can choose to use the Tensorflow or TFLite runtime (reccomended). To use the TFLite runtime, check out the guidance \href{https://ai.google.dev/edge/litert/microcontrollers/python}{\texttt{ here}}. Basic steps\+:

(On RPi) 
\begin{DoxyCode}{0}
\DoxyCodeLine{python3\ -\/m\ pip\ install\ tflite-\/runtime}

\end{DoxyCode}


Using Python, you can execute a quantised inference\+: 
\begin{DoxyCode}{0}
\DoxyCodeLine{import\ numpy\ as\ np}
\DoxyCodeLine{from\ tflite\_model\_runner\ import\ TFLiteModelRunner}
\DoxyCodeLine{}
\DoxyCodeLine{q\_model\ =\ TFLiteModelRunner.load\_tflite\_model("{}model\_weights/8/quant/8\_int8.tflite"{})}
\DoxyCodeLine{}
\DoxyCodeLine{input\_image\_array\ =\ np.random.uniform(0,\ 255,\ size=(q\_model.get\_input\_details()[0]["{}shape"{}][1:])).astype(np.uint8)}
\DoxyCodeLine{input\_image\_array\ =\ np.expand\_dims(input\_image\_array,\ axis=0)}
\DoxyCodeLine{}
\DoxyCodeLine{q\_model.set\_tensor(q\_model.get\_input\_details()[0]["{}index"{}],\ input\_image\_array)}
\DoxyCodeLine{q\_model.invoke()}
\DoxyCodeLine{}
\DoxyCodeLine{output\ =\ q\_model.get\_tensor(q\_model.get\_output\_details()[0]["{}index"{}])}
\DoxyCodeLine{print(output[0])\ \#\ remember\ that\ the\ output\ will\ be\ in\ confidence\ range\ 0-\/255}

\end{DoxyCode}


Using this example, you can load images into the {\ttfamily input\+\_\+image\+\_\+array}, by replacing the part using numpy, e.\+g. you could use \href{https://github.com/raspberrypi/picamera2}{\texttt{ Pi\+Camera}} to take images, and then process them with the model. {\ttfamily output\mbox{[}0\mbox{]}} will always contain the prediction from a given image, which is just given as an integer number. ~\newline


\end{adjustwidth}




{\bfseries{ESP32-\/\+S3}}\begin{adjustwidth}{1em}{0em}


Deploying models onto microcontroller platforms is a little more complicated, as these don\textquotesingle{}t usually support python, so we have to compile code from scratch to execute on each device. To make things as easy as possible, we have provided an example project which uses our models on ESP32s3 chipset with the Platformio extension for VSCode.

We have made a separate repository for this, which includes full guidance and further details.

\mbox{[}$<$\+Redacted for review$>$\mbox{]}(here)

\end{adjustwidth}


If you have not yet trained or quantised a model first, use one of ours developed for insect detection, or follow the our usage \doxysectlink{md_guides_2usage}{guidance}{0} to train your own. 